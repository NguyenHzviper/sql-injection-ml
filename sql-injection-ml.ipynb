{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-11-22T13:14:38.967409Z","iopub.status.busy":"2021-11-22T13:14:38.96648Z","iopub.status.idle":"2021-11-22T13:14:38.994955Z","shell.execute_reply":"2021-11-22T13:14:38.993808Z","shell.execute_reply.started":"2021-11-22T13:14:38.967308Z"},"id":"IMPVZK2F683D"},"source":["**IMPORTS**"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-16T06:16:18.164332Z","iopub.status.busy":"2023-09-16T06:16:18.163629Z","iopub.status.idle":"2023-09-16T06:16:29.199654Z","shell.execute_reply":"2023-09-16T06:16:29.198503Z","shell.execute_reply.started":"2023-09-16T06:16:18.164301Z"},"id":"TVBsdTmJ683J","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from nltk.corpus import stopwords\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import GaussianNB\n","import tensorflow as tf\n","from tensorflow.keras.utils import plot_model\n","from sklearn.metrics import RocCurveDisplay\n","from tensorflow.keras.layers import (\n","    Input,\n","    Embedding,\n","    Attention,\n","    LayerNormalization,\n","    Dense,\n",")\n","from sklearn import tree\n","from tensorflow import keras\n","from tensorflow.keras import models, layers\n","import warnings\n","\n","from sklearn.metrics import (\n","    confusion_matrix,\n","    classification_report,\n","    f1_score,\n","    precision_score,\n","    recall_score,\n","    accuracy_score,\n",")\n","from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support\n","import seaborn as sns\n","\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, roc_auc_score, auc\n","\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"zq84qpPI683M"},"source":["**LOADING AND PREPROCESSING DATASET**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:29.202218Z","iopub.status.busy":"2023-09-16T06:16:29.201608Z","iopub.status.idle":"2023-09-16T06:16:29.291840Z","shell.execute_reply":"2023-09-16T06:16:29.290677Z","shell.execute_reply.started":"2023-09-16T06:16:29.202188Z"},"id":"pwXfL2xxEwaM","outputId":"bd7f74bc-e2c4-4dab-c2cc-271e3a0e3f74","trusted":true},"outputs":[],"source":["path = './clean_data.csv'\n","df = pd.read_csv(path, encoding='utf-8')\n","print(\"Data Shape:\", df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:29.294639Z","iopub.status.busy":"2023-09-16T06:16:29.293793Z","iopub.status.idle":"2023-09-16T06:16:29.303983Z","shell.execute_reply":"2023-09-16T06:16:29.302811Z","shell.execute_reply.started":"2023-09-16T06:16:29.294572Z"},"id":"B6OuxIyx683N","outputId":"13d0213d-3e8a-444f-9c56-383a2f0fcbb8","trusted":true},"outputs":[],"source":["X = df['Sentence']\n","y = df['Label']\n","print(X.shape, y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:29.308515Z","iopub.status.busy":"2023-09-16T06:16:29.307786Z","iopub.status.idle":"2023-09-16T06:16:31.228445Z","shell.execute_reply":"2023-09-16T06:16:31.227378Z","shell.execute_reply.started":"2023-09-16T06:16:29.308478Z"},"id":"nNTZPR3jE3tX","outputId":"9f1daf8a-f316-4525-a4fb-77ea5da1385a","trusted":true},"outputs":[],"source":["import nltk\n","nltk.download('stopwords')\n","vectorizer = CountVectorizer(min_df = 2, max_df = 0.8, stop_words = stopwords.words('english'))\n","X = vectorizer.fit_transform(X.values.astype('U')).toarray()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:31.231432Z","iopub.status.busy":"2023-09-16T06:16:31.230708Z","iopub.status.idle":"2023-09-16T06:16:32.104169Z","shell.execute_reply":"2023-09-16T06:16:32.102934Z","shell.execute_reply.started":"2023-09-16T06:16:31.231393Z"},"id":"ab38XMjUE0ct","outputId":"0c6fab19-1669-4aaa-f345-4938c73eaa04","trusted":true},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2) #Train 80 Test 20"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:32.106250Z","iopub.status.busy":"2023-09-16T06:16:32.105864Z","iopub.status.idle":"2023-09-16T06:16:32.111956Z","shell.execute_reply":"2023-09-16T06:16:32.110754Z","shell.execute_reply.started":"2023-09-16T06:16:32.106214Z"},"id":"4tRntf4etCpz","trusted":true},"outputs":[],"source":["f1_dict = {}\n","precision_dict = {}\n","recall_dict = {}\n","accuracy_dict = {}\n","train_accuracy = {}\n","validation_accuracy = {}\n","test_accuracy = {}"]},{"cell_type":"markdown","metadata":{},"source":["## Support function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to plot the history graphs of the training and validation curves during training\n","def plot_history(history):\n","    history_dict = history.history\n","    train_loss = history_dict['loss']    # Training loss over epochs\n","    val_loss = history_dict['val_loss']    # Validation loss over epochs\n","    epochs = range(1, len(history_dict['loss'])+1)\n","    plt.plot(epochs, train_loss,'b', label='Training error')\n","    plt.plot(epochs, val_loss,'b', color=\"orange\", label='Validation error')\n","    plt.title('Training and Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","def plot_historyAcc(history):\n","    history_dict = history.history\n","    train_acc = history_dict['accuracy']    # Training loss over epochs\n","    val_acc = history_dict['val_accuracy']    # Validation loss over epochs\n","    epochs = range(1, len(history_dict['accuracy'])+1)\n","    plt.plot(epochs, train_acc,'b', label='Training accuracy')\n","    plt.plot(epochs, val_acc,'b', color=\"orange\", label='Validation accuracy')\n","    plt.title('Training and Validation Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    plt.show()\n","\n","# Function to plot the confusion matrix\n","def plot_confusion_matrix(conf_matrix):    \n","    fig, ax = plt.subplots(figsize=(7.5, 7.5))\n","    ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n","    for i in range(conf_matrix.shape[0]):\n","        for j in range(conf_matrix.shape[1]):\n","            ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n","    \n","    plt.xlabel('Predicted Value', fontsize=18)\n","    plt.ylabel('Actual Value', fontsize=18)\n","    plt.title('Confusion Matrix', fontsize=18)\n","    plt.show()\n","\n","def plot_roc_auc(model, X_test, y_test):\n","    # Predict probabilities for the positive class\n","    y_pred_proba = model.predict(X_test)\n","    \n","    # Extract probabilities for the positive class (assuming binary classification)\n","    if y_pred_proba.shape[1] > 1:\n","        y_pred_proba = y_pred_proba[:, 1]\n","    \n","    # Compute ROC curve\n","    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n","    roc_auc = auc(fpr, tpr)\n","\n","    # Plot ROC curve\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(fpr, tpr, label=f'{model.__class__.__name__} (AUC = {roc_auc:.2f})')\n","    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Classifier (AUC = 0.5)')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'ROC Curve for {model.name}')\n","    plt.legend(loc='lower right')\n","    plt.show()\n","\n","def plot_report(y_test, y_pred):\n","    conf_matrix_model = confusion_matrix(y_test, y_pred)\n","    plot_confusion_matrix(conf_matrix_model)\n","    print(classification_report(y_test, y_pred, target_names=[\"Non-Intrusion\", \"Intrusion\"]))"]},{"cell_type":"markdown","metadata":{},"source":["## Deep Learning"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_dl_model(\n","    model_name,\n","    X_train,\n","    y_train,\n","    X_test,\n","    y_test,\n","    af=\"sigmoid\",\n","    epochs=10,\n","    dense=64,\n","    learning_rate=0.01,\n","):\n","    X_train_dl = X_train.reshape(-1, 1, 6509)\n","    X_test_dl = X_test.reshape(-1, 1, 6509)\n","    train_shape = X_train_dl.shape[1:]\n","    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n","    if model_name == \"CNN\":\n","        model = models.Sequential(name=\"CNN\")\n","        model.add(layers.Conv1D(32, 1, activation=\"relu\", input_shape=train_shape))\n","        model.add(layers.Conv1D(32, 1, activation=\"relu\"))\n","        model.add(layers.Flatten())\n","        model.add(layers.Dense(1, activation=af))\n","        model.compile(\n","            optimizer=opt,\n","            loss=tf.keras.losses.BinaryCrossentropy(),\n","            metrics=[\"accuracy\"],\n","        )\n","    elif model_name == \"RNN\":\n","        model = models.Sequential(name=\"RNN\")\n","        model.add(\n","            layers.SimpleRNN(units=dense, activation=\"relu\", input_shape=train_shape)\n","        )\n","        model.add(layers.Dense(units=1, activation=af))\n","        model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","\n","    history = model.fit(\n","        X_train_dl,\n","        y_train,\n","        batch_size=32,\n","        epochs=epochs,\n","        validation_data=(X_test_dl, y_test),\n","    )\n","    y_pred = model.predict(X_test_dl).flatten()\n","    y_pred = np.round(y_pred)\n","    print(f\"Accuracy of {model_name} on test set : {accuracy_score(y_pred, y_test)}\")\n","    print(f\"F1 Score of {model_name} on test set : {f1_score(y_pred, y_test)}\")\n","\n","    # Updates model score to f1_dict\n","    f1_dict[f\"{model_name}\"] = f1_score(y_pred, y_test)\n","    precision_dict[f\"{model_name}\"] = precision_score(y_pred, y_test)\n","    recall_dict[f\"{model_name}\"] = recall_score(y_pred, y_test)\n","    accuracy_dict[f\"{model_name}\"] = accuracy_score(y_pred, y_test)\n","\n","    #! Plotting\n","    plot_history(history)\n","    plot_historyAcc(history)\n","    plot_roc_auc(model, X_test_dl, y_test)\n","    plot_report(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{},"source":["## Machine learning"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_ml_model(model_name, X_train, y_train, X_test, y_test):\n","    if model_name == \"LogisticRegression\":\n","        model = LogisticRegression()\n","    elif model_name == \"RandomForest\":\n","        model = RandomForestClassifier()\n","    elif model_name == \"SVM\":\n","        model = SVC(gamma=\"auto\")\n","    elif model_name == \"NaiveBayes\":\n","        model = GaussianNB()\n","    elif model_name == \"DecisionTree\":\n","        model = tree.DecisionTreeClassifier()\n","    else:\n","        print(\"Invalid model name\")\n","        return None\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    print(f\"Accuracy of {model_name} on test set : {accuracy_score(y_pred, y_test)}\")\n","    print(f\"F1 Score of {model_name} on test set : {f1_score(y_pred, y_test)}\")\n","    f1_dict[f\"{model_name}\"] = f1_score(y_pred, y_test)\n","    precision_dict[f\"{model_name}\"] = precision_score(y_pred, y_test)\n","    recall_dict[f\"{model_name}\"] = recall_score(y_pred, y_test)\n","    accuracy_dict[f\"{model_name}\"] = accuracy_score(y_pred, y_test)\n","    #!Plotting\n","    # ax = plt.gca()\n","    model_disp = RocCurveDisplay.from_estimator(model, X_test, y_test)\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Main"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["list_model_ml = [\n","    \"LogisticRegression\",\n","    \"RandomForest\",\n","    \"SVM\",\n","    \"NaiveBayes\",\n","    \"DecisionTree\",\n","]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","for model in list_model_ml:\n","    train_ml_model(model, X_train, y_train, X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["list_model_dl = [\n","    \"CNN\",\n","    \"RNN\",\n","]\n","#! Chỗ này để chỉnh kịch bản 1->5\n","scenarios = 1\n","for model in list_model_dl:\n","    if scenarios == 4 or scenarios == 5:\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n","        if scenarios == 5:\n","            train_dl_model(\n","                model, X_train, y_train, X_test, y_test, epochs=20\n","            )  # Chỉnh lại epochs\n","        else:\n","            train_dl_model(model, X_train, y_train, X_test, y_test)  # mặc định\n","    else:\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","        if scenarios == 1:\n","            train_dl_model(\n","                model, X_train, y_train, X_test, y_test, dense=256\n","            )  # Chỉnh lại dense\n","        elif scenarios == 2:\n","            train_dl_model(\n","                model, X_train, y_train, X_test, y_test, af=\"softmax\", epochs=20\n","            )\n","        else:\n","            train_dl_model(model, X_train, y_train, X_test, y_test)  # mặc định"]},{"cell_type":"markdown","metadata":{},"source":["# FINAL PLOT FOR MODELS PERFORMANCE "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T06:17:36.443224Z","iopub.status.idle":"2023-09-16T06:17:36.443737Z","shell.execute_reply":"2023-09-16T06:17:36.443487Z","shell.execute_reply.started":"2023-09-16T06:17:36.443463Z"},"id":"1KwQysSpT0wL","outputId":"8576f88b-979b-483a-fb23-241b1ecf436f","trusted":true},"outputs":[],"source":["keys2 = f1_dict, precision_dict, recall_dict, accuracy_dict\n","metrics = ['F1_Score', 'Precision', 'Recall', 'Accuracy']\n","data = pd.DataFrame(keys2)\n","data.index = metrics\n","data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T06:17:36.445516Z","iopub.status.idle":"2023-09-16T06:17:36.446014Z","shell.execute_reply":"2023-09-16T06:17:36.445784Z","shell.execute_reply.started":"2023-09-16T06:17:36.445760Z"},"id":"V7s1MQ3nT0ss","outputId":"0261f05b-f70b-4df5-c3ff-60e30a3ff732","trusted":true},"outputs":[],"source":["result = data.plot(kind='bar', rot=0, figsize=(15, 7));\n","result.legend(bbox_to_anchor=(1, 1.02), loc='upper left');"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":4}
